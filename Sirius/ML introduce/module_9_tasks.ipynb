{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baed4750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5857/1367877312.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/home/zea/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d039748-a647-403c-b3ac-1bbc03d91eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.33, 0.8, 0.77]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_first_task(ws, xs):\n",
    "    res = []\n",
    "    for x in xs:\n",
    "        x = [1] + x\n",
    "        scalar_prod = 0\n",
    "        for fac, w in zip(ws, x):\n",
    "            scalar_prod += fac * w\n",
    "        res.append(round(1 / (1 + math.exp(-scalar_prod)), 2))\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "compute_first_task(\n",
    "    [\n",
    "        0.1,\n",
    "        -0.2,\n",
    "        0.3\n",
    "    ],\n",
    "    [\n",
    "        [1, -2],\n",
    "        [-2, 3],\n",
    "        [-1, 3]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db13d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Классический набор данных для проверки качества работы алгоритмов классификации\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84257982",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (11.7, 8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab592d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_compare(x, y):\n",
    "    if str(x) != str(y):\n",
    "        raise RuntimeError(f'Ожидаемое значение: {y}. Фактическое: {x}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ee8d59",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "043333a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logistic_regression_predict_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5857/4123265774.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mlogistic_regression_predict_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'logistic_regression_predict_test' is not defined"
     ]
    }
   ],
   "source": [
    "def logistic_regression_predict_solution(w, data, factor_names):\n",
    "    \"\"\"\n",
    "    На основе переданного вектора весов для каждого объекта из\n",
    "    набора данных делает предсказание с помощью модели логистической регрессии.\n",
    "\n",
    "    Аргументы:\n",
    "        w: Вектор весов модели логистической регрессии. Первая координата вектора соответствует\n",
    "           свободному коэффициенту, последующие — весам факторов.\n",
    "        data: Таблица с объектами, для которых необходимо сделать предсказания.\n",
    "              Каждый объект описывается набором численных факторов.\n",
    "              В данных может быть представлено больше факторов, чем модель использует для предсказания.\n",
    "              Искусственного константного фактора, который для всех объектов равен `1` и\n",
    "              который используется моделью для предсказания, в таблице нет.\n",
    "        factor_names: Список названий факторов, которые используются для предсказания.\n",
    "                      Порядок названий совпадает с порядком, в котором идут коэффициенты факторов\n",
    "                      в векторе весов `w`.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "        Вектор предсказанных вероятностей принадлежности положительному классу для объектов из переданной таблицы.\n",
    "        Значения в векторе должны быть округлены до 2 знаков после запятой.\n",
    "    \"\"\"\n",
    "    xs = data[factor_names].to_numpy()\n",
    "    res = np.zeros(len(data))\n",
    "    for i in range(len(xs)):\n",
    "        scalar_prod = w[0]\n",
    "        for j in range(len(xs[i])):\n",
    "            scalar_prod += xs[i][j] * w[j + 1]\n",
    "        res[i] = (1 / (1 + math.exp(-scalar_prod)))\n",
    "    res = res.round(2)\n",
    "    return res\n",
    "    factors = data[factor_names].to_numpy()\n",
    "    factors_with_const = np.hstack((np.ones((factors.shape[0], 1)), factors))\n",
    "    z = np.dot(factors_with_const, w)\n",
    "    probabilities = 1 / (1 + np.exp(-z))\n",
    "    rounded_probabilities = np.round(probabilities, 2)\n",
    "    return rounded_probabilities\n",
    "\n",
    "\n",
    "logistic_regression_predict_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bc3d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_predict_test():\n",
    "    w_example_1 = np.array([0.1, 1])\n",
    "    data_example_1 = pd.DataFrame({\n",
    "        'x': [0.22, -0.41],\n",
    "    })\n",
    "\n",
    "    res_example_1 = np.array([0.58, 0.42])\n",
    "\n",
    "    custom_compare(logistic_regression_predict_solution(w_example_1, data_example_1, ['x']), res_example_1)\n",
    "\n",
    "    w_example_2 = np.array([0.1, 2.7, 2.3, -4.1])\n",
    "    data_example_2 = pd.DataFrame({\n",
    "        'x': [0.58, 0.15],\n",
    "        'extra': [1, 2],\n",
    "        'y': [0.58, 0.19],\n",
    "        'z': [0.93, 0.44]\n",
    "    })\n",
    "\n",
    "    res_example_2 = np.array([0.31, 0.3])\n",
    "\n",
    "    custom_compare(logistic_regression_predict_solution(w_example_2, data_example_2, ['x', 'y', 'z']), res_example_2)\n",
    "\n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87daaa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тест прошёл успешно!\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_predict_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886842b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_summary_loss_gradient_solution(w, X, y):\n",
    "    \"\"\"\n",
    "    Вычисляет градиент функции суммарных потерь в случае обучения модели логистической регрессии.\n",
    "\n",
    "    Аргументы:\n",
    "        w: Вектор весов модели логистической регрессии. Первая координата вектора соответствует\n",
    "           свободному коэффициенту, последующие — весам факторов.\n",
    "        X: Матрица значений факторов.\n",
    "           Первый столбец матрицы содержит значения константного коэффициента, который для всех объектов равен 1.\n",
    "           Колонке с индексом i в матрице соответствует вес с индексом i в векторе w.\n",
    "        y: Вектор классов, которым в реальности принадлежат объекты из матрицы X.\n",
    "           Объекту в i-ой строчке матрицы X соответствует значение с индексом i вектора y.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "        Вектор градиента функции суммарных потерь.\n",
    "        Каждая координата вектора должна быть округлена до 2 знаков после запятой.\n",
    "    \"\"\"\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8424fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_summary_loss_gradient_test():\n",
    "    w_example_1 = np.array([-0.2, -0.3])\n",
    "    X_example_1 = np.array([\n",
    "        [1, -2.1],\n",
    "        [1, 3.7]\n",
    "    ])\n",
    "\n",
    "    y_example_1 = np.array([-1, -1])\n",
    "\n",
    "    res_example_1 = np.array([0.82, -0.49])\n",
    "\n",
    "    custom_compare(logistic_summary_loss_gradient_solution(w_example_1, X_example_1, y_example_1), res_example_1)\n",
    "\n",
    "    w_example_2 = np.array([0.3, -0.1, 0.4])\n",
    "    X_example_2 = np.array([\n",
    "        [1, 0.1, 0.3],\n",
    "        [1, -0.2, 0.5]\n",
    "    ])\n",
    "\n",
    "    y_example_2 = np.array([1, -1])\n",
    "\n",
    "    res_example_2 = np.array([0.23, -0.17,  0.19])\n",
    "\n",
    "    custom_compare(logistic_summary_loss_gradient_solution(w_example_2, X_example_2, y_example_2), res_example_2)\n",
    "\n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03491b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_summary_loss_gradient_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5777680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_solve_solution(data, factor_names, y_name,\n",
    "                                       learning_rate=0.01, eps=0.1):\n",
    "    \"\"\"\n",
    "    С помощью градиентного спуска строит модель логистической регрессии по переданному набору данных.\n",
    "\n",
    "    Аргументы:\n",
    "        data: Таблица с объектами обучающей выборки.\n",
    "              Каждый объект описывается набором численных факторов.\n",
    "              В данных может быть представлено больше факторов, чем модель должна использовать для предсказания.\n",
    "              Искусственного константного фактора, который для всех объектов равен 1 и\n",
    "              который будет использоваться моделью для предсказания, в таблице нет.\n",
    "        factor_names: Список названий факторов, которые модель должна использовать для предсказания.\n",
    "        y_name: Название столбца таблицы, в котором для каждого объекта содержится значение предсказываемого класса.\n",
    "                Класс может иметь значение либо -1, либо 1.\n",
    "        learning_rate: Опциональный параметр. Коэффициент скорости обучения, который используется в алгоритме градиентного спуска.\n",
    "        eps: Опциональный параметр. Минимальное расстояние между текущей точкой градиентного спуска и следующей,\n",
    "             при котором работа алгоритма останавливается.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "        Возвращает вектор весов модели.\n",
    "        Координата вектора с индексом 0 соответствует свободному коэффициенту модели.\n",
    "        Координата вектора с индексом i соответствует фактору с индексом i - 1 в списке factor_names.\n",
    "    \"\"\"\n",
    "\n",
    "    X = data[factor_names].to_numpy()\n",
    "    y = data[y_name].to_numpy()\n",
    "\n",
    "    ones = np.ones((len(y), 1))\n",
    "\n",
    "    X = np.hstack([ones, X])\n",
    "\n",
    "    # Необходимо задать стартовый набор весов, который является начальной\n",
    "    # точкой для алгоритма градиентного спуска.\n",
    "    # В качестве стартового набора весов необходимо использовать вектор, состоящий из значений 0\n",
    "    w_cur = None\n",
    "\n",
    "    while True:\n",
    "        # Вычисление градиента с помощью функции logistic_summary_loss_gradient_solution.\n",
    "        # Важно убрать округление результата работы функции до 2 знаков после запятой\n",
    "        gradient_value = None\n",
    "\n",
    "        # Полезно уменьшить значение градиента, разделив каждую его координату на число объектов\n",
    "        # в выборке, на которой происходит обучение модели\n",
    "        gradient_value /= len(y)\n",
    "\n",
    "        # Классический шаг градиентного спуска: переход из текущей точки в направлении,\n",
    "        # противоположном вектору градиента\n",
    "        w_new = None\n",
    "\n",
    "        # Проверка того, что расстояние между текущей точкой и новой не стало меньше или равно eps\n",
    "        if None:\n",
    "            break\n",
    "\n",
    "        w_cur = w_new\n",
    "\n",
    "    return w_cur.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2834df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_solve_test():\n",
    "    data_example_1 = pd.DataFrame({\n",
    "        'x1': [0.3, -0.1, -0.1, 0.4],\n",
    "        'x2': [0.1, -0.1, 0.2, -0.1],\n",
    "        'y': [1, -1, -1, 1],\n",
    "    })\n",
    "\n",
    "    factor_names_example_1 = ['x1', 'x2']\n",
    "    y_name_example_1 = 'y'\n",
    "\n",
    "    res_example_1 = np.array([-0.07, 0.94, -0.1])\n",
    "\n",
    "    custom_compare(logistic_regression_solve_solution(data_example_1, factor_names_example_1, y_name_example_1,\n",
    "                                                      learning_rate=0.001, eps=0.0001),\n",
    "                  res_example_1)\n",
    "\n",
    "\n",
    "    iris = load_iris()\n",
    "\n",
    "    y_example_2 = (iris.target >= 1).astype('int64').reshape((len(iris.target), 1))\n",
    "    y_example_2[y_example_2 == 0] = -1\n",
    "\n",
    "    factor_names_example_2 = ['x1', 'x2']\n",
    "    y_name_example_2 = 'y'\n",
    "\n",
    "    data_example_2 = pd.DataFrame(\n",
    "        columns=['x1', 'x2', 'x3', 'x4'] + [y_name_example_2],\n",
    "        data=np.hstack([iris.data, y_example_2])\n",
    "    )\n",
    "\n",
    "    res_example_2 = np.array([-0.23,  1.17, -1.83])\n",
    "\n",
    "    custom_compare(logistic_regression_solve_solution(data_example_2, factor_names_example_2, y_name_example_2,\n",
    "                                                      learning_rate=0.01, eps=0.001),\n",
    "                   res_example_2)\n",
    "\n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65d509b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_solve_res():\n",
    "    # Загрузка набора данных для тестирования алгоритмов классификации\n",
    "    iris = load_iris()\n",
    "\n",
    "    # Приведение классов, которые необходимо научиться предсказывать, к значениям -1 и 1\n",
    "    y = (iris.target > 1).astype('int64').reshape((len(iris.target), 1))\n",
    "    y[y == 0] = -1\n",
    "\n",
    "    # Создание таблицы на основе набора данных.\n",
    "    # Факторы, которые есть в данных, будут называться 'x1', 'x2', 'x3' и 'x4'.\n",
    "    # Классы объектов помещаются в колонку 'y'\n",
    "    data = pd.DataFrame(\n",
    "        columns=['x1', 'x2', 'x3', 'x4', 'y'],\n",
    "        data=np.hstack([iris.data, y])\n",
    "    )\n",
    "\n",
    "    # Для предсказания будут использоваться только факторы 'x1' и 'x2'\n",
    "    factor_names = ['x1', 'x2']\n",
    "    # Предсказываемая характеристика — 'y'\n",
    "    y_name = 'y'\n",
    "\n",
    "    # Определение оптимальных весов для разработанной модели логистической регрессии\n",
    "    ws = logistic_regression_solve_solution(data, factor_names, y_name,\n",
    "                                            learning_rate=0.01, eps=0.001)\n",
    "\n",
    "    for i in range(len(ws)):\n",
    "        print(f'w{i}:', ws[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7502a459",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /=: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlogistic_regression_solve_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m, in \u001b[0;36mlogistic_regression_solve_test\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m y_name_example_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     11\u001b[0m res_example_1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.07\u001b[39m, \u001b[38;5;241m0.94\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.1\u001b[39m])\n\u001b[1;32m---> 13\u001b[0m custom_compare(\u001b[43mlogistic_regression_solve_solution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_example_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor_names_example_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_name_example_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     15\u001b[0m               res_example_1)\n\u001b[0;32m     18\u001b[0m iris \u001b[38;5;241m=\u001b[39m load_iris()\n\u001b[0;32m     20\u001b[0m y_example_2 \u001b[38;5;241m=\u001b[39m (iris\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;28mlen\u001b[39m(iris\u001b[38;5;241m.\u001b[39mtarget), \u001b[38;5;241m1\u001b[39m))\n",
      "Cell \u001b[1;32mIn[8], line 44\u001b[0m, in \u001b[0;36mlogistic_regression_solve_solution\u001b[1;34m(data, factor_names, y_name, learning_rate, eps)\u001b[0m\n\u001b[0;32m     40\u001b[0m gradient_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Полезно уменьшить значение градиента, разделив каждую его координату на число объектов\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# в выборке, на которой происходит обучение модели\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m \u001b[43mgradient_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Классический шаг градиентного спуска: переход из текущей точки в направлении,\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# противоположном вектору градиента\u001b[39;00m\n\u001b[0;32m     48\u001b[0m w_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /=: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "logistic_regression_solve_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_solve_res()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
