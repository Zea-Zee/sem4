{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49e42b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from math import floor, exp, sqrt, pi, cos, sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7021e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка библиотеки sklearn\n",
    "!pip3 install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8a62b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f3a03c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_2(x):\n",
    "    \"\"\"\n",
    "    Принимает число и возвращает результат его округления\n",
    "    до 2 знаков после запятой.\n",
    "\n",
    "    Аргументы:\n",
    "        x: Число.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "        Результат округления числа до 2 знаков после запятой.\n",
    "    \"\"\"\n",
    "\n",
    "    return round(x, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e364ebb7",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7e0114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, x_val, y_val):\n",
    "    \"\"\"\n",
    "    Оценивает точность модели по метрике «среднее отклонение от предсказанного значения».\n",
    "\n",
    "    Аргументы:\n",
    "        model: Модель.\n",
    "        x_test: Список объектов тестовой выборки.\n",
    "        y_test: Список значений предсказываемой характеристики для объектов из тестовой выборки.\n",
    "                Значение на $i$-й позиции в списке соответствует $i$-му объекту тестовой выборки.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "        Возвращает точность модели.\n",
    "    \"\"\"\n",
    "\n",
    "    y_pred = model.predict(x_val)\n",
    "\n",
    "    res = 0\n",
    "\n",
    "    for i in range(len(y_val)):\n",
    "        res += abs(y_pred[i] - y_val[i])\n",
    "\n",
    "    return res / len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "625aa87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_solution(model,\n",
    "                         model_configs,\n",
    "                         x_train, y_train,\n",
    "                         x_val, y_val):\n",
    "    \"\"\"\n",
    "    Принимает набор конфигураций модели линейной регрессии и находит лучшую из них\n",
    "    с помощью алгоритма grid search.\n",
    "    Для оценки точности модели на валидационной выборке используется функция score_model.\n",
    "\n",
    "    Аргументы:\n",
    "        model: Модель.\n",
    "        model_configs: Список конфигураций модели линейной регрессии.\n",
    "                       Каждая конфигурация — список номеров факторов,\n",
    "                       которые используются для обучения модели.\n",
    "        x_train: Список объектов обучающей выборки.\n",
    "        y_train: Список значений предсказываемой характеристики для объектов из обучающей выборки.\n",
    "                 Значение на $i$-й позиции в списке соответствует $i$-му объекту обучающей выборки.\n",
    "        x_val: Список объектов валидационной выборки.\n",
    "        y_val: Список значений предсказываемой характеристики для объектов из валидационной выборки.\n",
    "               Значение на $i$-й позиции в списке соответствует $i$-му объекту валидационной выборки.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "        Возвращает пару значений: лучшая конфигурация, точность модели с данной конфигурацией\n",
    "        на валидационной выборке.\n",
    "    \"\"\"\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "357cd49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_path, frac=0.9):\n",
    "    data_x_y = []\n",
    "\n",
    "    with open(file_path) as f:\n",
    "        cnt = 0\n",
    "\n",
    "        for line in f:\n",
    "            if cnt == 0:\n",
    "                cnt += 1\n",
    "                continue\n",
    "\n",
    "            l = line.strip().split(',')\n",
    "            data_x_y.append(([float(x) for x in l[:-1]], float(l[-1])))\n",
    "\n",
    "            cnt += 1\n",
    "\n",
    "    cut_n = floor(frac * len(data_x_y))\n",
    "\n",
    "    train_x_y = data_x_y[:cut_n]\n",
    "    val_x_y = data_x_y[cut_n:]\n",
    "\n",
    "    train_x, train_y = [], []\n",
    "\n",
    "    for x, y in train_x_y:\n",
    "        train_x.append(x)\n",
    "        train_y.append(y)\n",
    "\n",
    "    val_x, val_y = [], []\n",
    "\n",
    "    for x, y in val_x_y:\n",
    "        val_x.append(x)\n",
    "        val_y.append(y)\n",
    "\n",
    "    return train_x, train_y, val_x, val_y\n",
    "\n",
    "def grid_search_test():\n",
    "    def split_df_to_xs_and_ys(df):\n",
    "        xs = []\n",
    "        ys = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            xs.append([row['x1'], row['x2'], row['x3'], row['x4']])\n",
    "            ys.append(row['y'])\n",
    "\n",
    "        return xs, ys\n",
    "\n",
    "    data_x_train_example_1 = [[1, -33], [2, -21], [3, -34234]]\n",
    "    data_y_train_example_1 = [1, 2, 3]\n",
    "\n",
    "    data_x_val_example_1 = [[4, -231], [5, -342341], [6, -23]]\n",
    "    data_y_val_example_1 = [4, 5, 6]\n",
    "\n",
    "    configs_example_1 = [[0], [1]]\n",
    "\n",
    "    res_example_1 = ([0], 0)\n",
    "\n",
    "    assert grid_search_solution(LinearRegression(),\n",
    "                                configs_example_1,\n",
    "                                data_x_train_example_1, data_y_train_example_1,\n",
    "                                data_x_val_example_1, data_y_val_example_1) == res_example_1\n",
    "\n",
    "    data_x_train_example_2, data_y_train_example_2, \\\n",
    "        data_x_val_example_2, data_y_val_example_2 = process_data('grid_search_test_data.csv', frac=0.9)\n",
    "\n",
    "    configs_example_2 = [[0], [0, 1], [0, 1, 2], [2, 3], [1]]\n",
    "\n",
    "    res_example_2 = ([0, 1, 2], 0.26)\n",
    "\n",
    "    assert grid_search_solution(LinearRegression(),\n",
    "                                configs_example_2,\n",
    "                                data_x_train_example_2, data_y_train_example_2,\n",
    "                                data_x_val_example_2, data_y_val_example_2) == res_example_2\n",
    "\n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02796d4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16758/1080268406.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_search_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_16758/4048063955.py\u001b[0m in \u001b[0;36mgrid_search_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mres_example_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     assert grid_search_solution(LinearRegression(),\n\u001b[0m\u001b[1;32m     58\u001b[0m                                 \u001b[0mconfigs_example_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                                 \u001b[0mdata_x_train_example_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y_train_example_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LinearRegression' is not defined"
     ]
    }
   ],
   "source": [
    "grid_search_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aacba8e",
   "metadata": {},
   "source": [
    "# Метод дихотомии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93a680a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dichotomous_search_solution(f, a, b, eps):\n",
    "    \"\"\"\n",
    "    Производит поиск минимума заданной функции в заданном интервале с помощью метода дихотомии.\n",
    "\n",
    "    Аргументы:\n",
    "        f: Функция от одного аргумента, минимум которой необходимо найти.\n",
    "        a: Левая граница интервала, в котором происходит поиск минимума.\n",
    "        b: Правая граница интервала, в котором происходит поиск минимума.\n",
    "        eps: Допустимая погрешность при поиске минимума.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "        Возвращает координату точки, в которой достигается минимальное значение функции.\n",
    "        Координата должна быть округлена до 2 знаков после запятой.\n",
    "    \"\"\"\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "576aeefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dichotomous_search_test():\n",
    "    f_example_1 = lambda x: x ** 2\n",
    "\n",
    "    a_example_1 = -2\n",
    "    b_example_1 = 5\n",
    "    eps_example_1 = 0.01\n",
    "\n",
    "    res_example_1 = 0\n",
    "\n",
    "    min_example_1 = dichotomous_search_solution(f_example_1, a_example_1, b_example_1, eps_example_1)\n",
    "\n",
    "    if min_example_1 == 0.0:\n",
    "        min_example_1 = abs(min_example_1)\n",
    "\n",
    "    assert min_example_1 == res_example_1\n",
    "\n",
    "    f_example_2 = lambda x: (exp(2 * (x - 2)) + 1) * (x + 1) ** 2\n",
    "\n",
    "    a_example_2 = -100\n",
    "    b_example_2 = 200\n",
    "    eps_example_2 = 0.01\n",
    "\n",
    "    res_example_2 = -1\n",
    "\n",
    "    min_example_2 = dichotomous_search_solution(f_example_2, a_example_2, b_example_2, eps_example_2)\n",
    "\n",
    "    if min_example_2 == 0.0:\n",
    "        min_example_2 = abs(min_example_2)\n",
    "\n",
    "    assert min_example_2 == res_example_2\n",
    "\n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8b023a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16758/1696912120.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdichotomous_search_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_16758/2091603422.py\u001b[0m in \u001b[0;36mdichotomous_search_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmin_example_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_example_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mmin_example_1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mres_example_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mf_example_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dichotomous_search_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b65f9ac",
   "metadata": {},
   "source": [
    "# Градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee277984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_solution(grad_f, x_0, alpha, eps):\n",
    "    \"\"\"\n",
    "    Производит поиск минимума заданной функции двух аргументов с помощью градиентного спуска.\n",
    "\n",
    "    Аргументы:\n",
    "        grad_f: Градиент функции двух аргументов, для которой необходимо найти минимум.\n",
    "                Функция принимает на вход точку (список из двух значений) и возвращает\n",
    "                вектор градиента в этой точке (тоже список из двух значений).\n",
    "        x_0: Стартовая точка (список из двух значений), из которой запускается алгоритм градиентного спуска.\n",
    "        alpha: Коэффициент скорости обучения.\n",
    "        eps: Минимальное расстояние между текущей точкой градиентного спуска и следующей,\n",
    "             при котором работа алгоритма останавливается.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "        Координаты точки (список из двух значений), в которой достигается минимальное значение функции.\n",
    "        Каждая координата должна быть округлена до 2 знаков после запятой.\n",
    "    \"\"\"\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b731c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_test():\n",
    "    f_example_1 = lambda x: 2 * x[0] ** 2 + 2 * x[1] ** 2\n",
    "    grad_f_example_1 = lambda x: [4 * x[0], 4 * x[1]]\n",
    "\n",
    "    x_0_example_1 = [32, -4]\n",
    "\n",
    "    alpha_example_1 = 0.01\n",
    "    eps_example_1 = 0.001\n",
    "\n",
    "    res_example_1 = [0.02, 0]\n",
    "\n",
    "    assert gradient_descent_solution(grad_f_example_1, x_0_example_1, alpha_example_1, eps_example_1) == res_example_1\n",
    "\n",
    "    f_example_2 = lambda x: (x[0] - 1) ** 4 + 2 * (x[1] + 2) ** 2 - 1\n",
    "    grad_f_example_2 = lambda x: [4 * (x[0] - 1) ** 3, 4 * (x[1] + 2)]\n",
    "\n",
    "    x_0_example_2 = [-2, 2]\n",
    "\n",
    "    alpha_example_2 = 0.0001\n",
    "    eps_example_2 = 0.0001\n",
    "\n",
    "    res_example_2 = [0.58, -1.76]\n",
    "\n",
    "    assert gradient_descent_solution(grad_f_example_2, x_0_example_2, alpha_example_2, eps_example_2) == res_example_2\n",
    "\n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4a55763",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16758/1846566676.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgradient_descent_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_16758/1590980625.py\u001b[0m in \u001b[0;36mgradient_descent_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mres_example_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mgradient_descent_solution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_f_example_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_0_example_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_example_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps_example_1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mres_example_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mf_example_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gradient_descent_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e68b85",
   "metadata": {},
   "source": [
    "# Метод имитации отжига"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28a7759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    return 2 * x ** 2 + cos(pi * x) - 2.9 * sin(2 * pi * x) + cos(3 * pi * x) * sin(pi * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18fe0d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_with_p(random_gen, p, new_x, x):\n",
    "    \"\"\"\n",
    "    С заданной вероятностью возвращает точку `new_x`, в остальных случаях\n",
    "    возвращает точку x.\n",
    "\n",
    "    Аргументы:\n",
    "        random_gen: Генератор случайных чисел.\n",
    "        p: Вероятность, с которой нужно вернуть первую точку.\n",
    "        new_x: Точка, которая возвращается с вероятностью p.\n",
    "        x: Точка, которая возвращает в остальных случаях.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "        Точка, которая с вероятностью p будет равна new_x. В противном случае точка будет равна x.\n",
    "    \"\"\"\n",
    "\n",
    "    val = random_gen.random()\n",
    "\n",
    "    if val > p:\n",
    "        return x\n",
    "\n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "16e88d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.002285364088266739 0.0010361621429613166\n",
      "Тест прошёл успешно!\n",
      "-0.7066310355826833 -3.13960803122356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.71"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def simulated_annealing_solution(f, x_0, t_0, lam, eps, random_gen):\n",
    "    \"\"\"\n",
    "    Производит поиск минимума функции с помощью метода имитации отжига.\n",
    "\n",
    "    Аргументы:\n",
    "        f: Функция, минимум которой необходимо найти.\n",
    "        x_0: Стартовая точка, из которой начинается процесс поиска минимума.\n",
    "        t_0: Начальная температура системы.\n",
    "        lam: Коэффициент охлаждения системы на каждом шаге.\n",
    "             Охлаждение происходит по правилу T = lam * T.\n",
    "        eps: Когда температура становится меньше eps, метод имитации отжига останавливает свою работу.\n",
    "        random_gen: Генератор случайных чисел.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "        Точка, которую метод считает минимумом функции.\n",
    "    \"\"\"\n",
    "    while t_0 > eps:\n",
    "        x_1 = x_0 + random_gen.random() * 2 - 1\n",
    "        if f(x_1) >= f (x_0):\n",
    "            p = exp(-((f(x_1) - f(x_0)) / t_0))\n",
    "            x_1 = sub_with_p(random_gen, p, x_1, x_0)\n",
    "        x_0 = x_1\n",
    "        t_0 *= lam\n",
    "    print(x_1, f(x_1))\n",
    "    return round_to_2(x_1)\n",
    "\n",
    "\n",
    "simulated_annealing_test()\n",
    "simulated_annealing_solution(lambda x: 2 * (x ** 2) + cos(math.pi * x) - 2.9 * sin(2 * math.pi * x) + cos(3 * math.pi *x) * sin(math.pi * x), 0, 10000000, 0.999, 0.00001, random.Random(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd77b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_annealing_test():\n",
    "    weierstrass_function = lambda x: 10 + x ** 2 - 10 * cos(2 * pi * x)\n",
    "\n",
    "    f_example_1 = weierstrass_function\n",
    "\n",
    "    x_0_example_1 = 20\n",
    "    t_0_example_1 = 1000\n",
    "    lam_example_1 = 0.99\n",
    "    eps_example_1 = 0.001\n",
    "\n",
    "    random_gen_example_1 = random.Random(0)\n",
    "\n",
    "    res_example_1 = 0.0\n",
    "\n",
    "    found_min_example_1 = \\\n",
    "        simulated_annealing_solution(weierstrass_function,\n",
    "                                     x_0_example_1,\n",
    "                                     t_0_example_1,\n",
    "                                     lam_example_1,\n",
    "                                     eps_example_1,\n",
    "                                     random_gen_example_1)\n",
    "\n",
    "    assert round_to_2(weierstrass_function(found_min_example_1)) == res_example_1\n",
    "\n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b62b94fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тест прошёл успешно!\n"
     ]
    }
   ],
   "source": [
    "simulated_annealing_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03472852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Минимум функции g(x) равен: -2.76\n",
      "Он достигается при x = 0.3\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "from math import cos, sin, pi\n",
    "\n",
    "def g(x):\n",
    "    return 2*x**2 + cos(pi*x) - 2.9*sin(2*pi*x) + cos(3*pi*x)*sin(pi*x)\n",
    "\n",
    "# Найти минимум функции g(x)\n",
    "result = minimize_scalar(g, method='bounded', bounds=(-10, 10))\n",
    "\n",
    "# Вывести результат\n",
    "print('Минимум функции g(x) равен:', round(result.fun, 2))\n",
    "print('Он достигается при x =', round(result.x, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92c5002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
